{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalance Class\n",
    "\n",
    "1) Undersampling Methods\n",
    "1. **Undersampling Majority** - undersampling randomly discarding majority class observations to balance training sample\n",
    "    * (+) reduces runtime on very large datasets\n",
    "    * (-) discards potentially important observations\n",
    "    * (-) increases bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Oversampling Methods\n",
    "1. **Oversampling Minority** - oversampling replicates observations from minority class to balance training sample\n",
    "    * (+) doesn't discard information\n",
    "    * (-) increases variance (more likely to overfit)\n",
    "    * (-) SMOTE is usually a better oversampling technique\n",
    "2. **Synthetic Minority Oversampling Technique (SMOTE)** - randomly generate new observations from minority class using kNN (modal of neighbor $k$)\n",
    "    * for each minority class observation and for each feature, randomly generate between it and one of its k-nearest neighbors\n",
    "    * randomly assign a weight $w$ based on $k$ neighbor\n",
    "    * nearest neighbor $(1-w)$\n",
    "    * SMOTE pseudecode:\n",
    "```python\n",
    "synthetic_observations = []\n",
    "while len(synthetic_observations) + len(minority_observations) < target:\n",
    "    obs = random.choice(minority_observations): \n",
    "    neighbor = random.choice(kNN(obs, k)) # randomly selected neighbor\n",
    "    new_observation = {}\n",
    "    for feature in obs:\n",
    "        weight = random() # random float between 0 and 1\n",
    "        new_feature_value = weight*obs[feature] \\\n",
    "                            + (1-weight)*neighbor[feature]\n",
    "        new_observation[feature] = new_feature_value\n",
    "    synthetic_observations.append(new_observation)\n",
    "```\n",
    "3. **Random Oversampling Examples (ROSE)** - look at observation and establish kernel density, and draw from its probability distribution to get a synthetic observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Sampling Technique Intuition\n",
    "* What's the right amount of oversampling/undersampling?\n",
    "    * If you know the cost-benefit matrix, then maximize profit curve over target proportion to determine right amount of sampling\n",
    "    * If you **don't** know the cost-benefit matrix, there is no clear answer; however, ROC's AUC might be more useful to determine right amount of sampling\n",
    "* Cost Sensitivity vs. Sampling:\n",
    "    * Neither is strictly superior\n",
    "    * Generally, oversampling tends to work **better** than undersampling on small datasets\n",
    "    * Some algorithms don't have an obvious cost-sensitive adaptation, thus requiring sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
